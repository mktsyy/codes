{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39356887\n",
      "0.018228836\n",
      "0.009783\n",
      "0.0076267114\n",
      "0.0065534855\n",
      "0.005906962\n",
      "0.0054392847\n",
      "0.005102392\n",
      "0.004768477\n",
      "0.0044598444\n",
      "0.0041985465\n",
      "0.003971977\n",
      "0.00378623\n",
      "0.003650204\n",
      "0.0035530035\n",
      "0.0034778991\n",
      "0.0034226077\n",
      "0.0033739232\n",
      "0.003334895\n",
      "0.0033032936\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def add_layer(inputs,in_size,out_size,activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size,out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1,out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs,Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs\n",
    "\n",
    "x_data = np.linspace(-1,1,300)[:,np.newaxis]\n",
    "noise = np.random.normal(0,0.05,x_data.shape)\n",
    "y_data = np.square(x_data)-0.5 + noise\n",
    "\n",
    "xs = tf.placeholder(tf.float32,[None,1])\n",
    "ys = tf.placeholder(tf.float32,[None,1])\n",
    "l1 = add_layer(xs,1,10,activation_function=tf.nn.relu)\n",
    "prediction = add_layer(l1,10,1,activation_function=None)\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),reduction_indices=[1]))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(train_step,feed_dict={xs:x_data,ys:y_data})\n",
    "    if i % 50 == 0:\n",
    "        print (sess.run(loss,feed_dict={xs:x_data,ys:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47040000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADqNJREFUeJzt3X+QVfV5x/HPA7ICq0HUqAzSkKhJymCzki1jS5sSow4yOmjb6NLUIWno2gaSZmKbWjtTtWNnGNskTW1jukES1PgjNRqZjG1E+oNkog6rQd2IEetsECGsioHFqLDu0z/2kK6453sv9557z2Wf92uG2XvPc773PHOWz5577zn3fs3dBSCeCWU3AKAchB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFBHNXNj1jbJNaWtmZsEYnltv3z/Aatm1brCb2aLJH1Z0kRJq919VXLAlDbZ2XPr2SSABH+4r+p1a37ab2YTJf2LpAskzZG01Mzm1Pp4AJqrntf88yU96+7Puft+SXdKWlJMWwAarZ7wz5T0/Kj727Nlb2Fm3WbWa2a92j9Ux+YAFKme8I/1psLbPh/s7j3u3ununWpr6vuLABLqCf92SbNG3T9V0o762gHQLPWEf5OkM8zs3WbWJqlL0rpi2gLQaDU/D3f3ITNbKel7GjnVt8bdf1xYZwAaqq4X4e5+v6T7C+oFQBNxeS8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTGFDuozb2GyfNu5y3NrXb8xOzn2zof6k/U/XN+TrOtHG9P14DjyA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ5u61DzbrlzQo6U1JQ+7emVx/Wrvb2XNr3h5K0LEgWR78i+uT9SlTG3cpyWu/OJCsH/uxcxq27VblD/fJ97xq1axbxG/mw+7+UgGPA6CJeNoPBFVv+F3SA2b2qJl1F9EQgOao92n/AnffYWYnSVpvZk+7+1suqM7+KIz8YZjcVufmABSlriO/u+/Ifg5IulfS/DHW6XH3TnfvVBufIwJaRc3hN7N2Mzv24G1J50vqK6oxAI1Vz6H4ZEn3mtnBx7nd3f+jkK4ANFzN4Xf35yR9oMBeUIbO85Lllz/1+WR9ytRJFTaQfx3J668NJUcODQ0n68ccW+E9pPkX5Nce35Ae+8b+dH0c4FQfEBThB4Ii/EBQhB8IivADQRF+ICguuRsP2qfm1848Nzn0xeUrk/Vp0yfX0lFVtg/sS9YXf/f7yfozKy5K1of+6q9za5+4Nz321ls+layPBxz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAozvOPA3d9ZnVu7ffmz2piJ4fn9Hcdl6yf0HZisr75mfSXRne89525td+dNT059tZkdXzgyA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQXGe/0gwb2GyvHjujES1qtmacz2+9cVk/frHnk/W/+2yebm1PT9/LTl20wvfSdYv+t4Hk/UX3t+VW7P6dsu4wJEfCIrwA0ERfiAowg8ERfiBoAg/EBThB4KqeJ7fzNZIulDSgLvPzZYdL+kuSbMl9Uu61N1faVyb41zHgmR58MprkvUpU1O/xvwpsiVpY9/PkvVz/v6PkvUT5v1Bsv7xeybm1m578G+TY7VzV7qsHybrw5++LLd2/pmpayMknfWhdP1HG9P1I0A1R/5vSFp0yLKrJG1w9zMkbcjuAziCVAy/u2+UtPuQxUskrc1ur5V0ccF9AWiwWl/zn+zuOyUp+3lScS0BaIaGX9tvZt2SuiVJk9savTkAVar1yL/LzGZIUvZzIG9Fd+9x905371QbnyMCWkWt4V8naVl2e5mk+4ppB0CzVAy/md0h6SFJ7zOz7Wb2SUmrJJ1nZlslnZfdB3AEqfg83N2X5pQ+UnAv49ecucny3YtXJOtTpk5K1vcNvpFbe3nP68mxy/9nU7KuvYPJ8sv//a/J+m3pRy9NW1v+9QeSdPcFf5Ks/36Q8/wAxiHCDwRF+IGgCD8QFOEHgiL8QFBccleEyUcnyxu60h/J/Z0zT0nW33j9QLJ+6ur8CaX3Pf3d5Fi1T03Xg3rvCe1lt9BwHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjO8xfh185Jliudx6+k/cYb0yv88J66Hh8xceQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaA4z1+Avq4/rbCGJauPb30xPZzz+DWZMCF/vw8Pp8emf2PjA0d+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiq4nl+M1sj6UJJA+4+N1t2raQ/lnTwBPXV7n5/o5psBScuzJ+y+fRZ0yqM9mT1ut5tNXSESoaHU/s9/TtZv+2VYptpQdUc+b8hadEYy7/k7h3Zv3EdfGA8qhh+d98oaXcTegHQRPW85l9pZk+Y2Rozm15YRwCaotbw3yTpNEkdknZK+kLeimbWbWa9Ztar/UM1bg5A0WoKv7vvcvc33X1Y0tckzU+s2+Pune7eqTY+RwS0iprCb2YzRt29RFJfMe0AaJZqTvXdIWmhpBPNbLukayQtNLMOjZwv6Zd0RQN7BNAAFcPv7kvHWHxzA3ppadMmHZdbO+qo9BOowT1vJOvrHrqhpp7GvclHJ8t/vuyfa37o3qfT36Hwua9/uubHPlJwhR8QFOEHgiL8QFCEHwiK8ANBEX4gKC65a4IDB95Mr/D8C81ppNVUOJW38vL01OSrFr0/Wf/57l/k1s7993XJsdo7mK6PAxz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAozvM3wZondpTdQnk6FuSW7l68Ijn04l+flaw/sDm9Xxdfd1myHh1HfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivP8VZogS1RTNWl5x8xk/aoa+mkVl3T9U7J+y0Vn5tamTJ2UHHv3Iz9N1rtWfSxZRxpHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IquJ5fjObJekWSadIGpbU4+5fNrPjJd0labakfkmXuvsrjWu1XMPyRDVVk95x3ORk/YbPfD1Z//zG1cm69m7PLZ122lgzrP+/nt/+YLL+gZnTkvXjjp+arO9+6dXc2oNP/Sw5tmvDrck66lPNkX9I0pXu/quSzpa0wszmaOTalA3ufoakDTqyr1UBwqkYfnff6e6PZbcHJW2RNFPSEklrs9XWSrq4UU0CKN5hveY3s9mSzpL0iKST3X2nNPIHQtJJRTcHoHGqvrbfzI6R9G1Jn3X3vWbp69lHjeuW1C1JmtxWQ4sAGqGqI7+ZTdJI8L/p7vdki3eZ2YysPkPSwFhj3b3H3TvdvVNtfI4IaBUVw28jh/ibJW1x9y+OKq2TtCy7vUzSfcW3B6BRqjkUL5B0uaQnzWxztuxqSaskfcvMPilpm6SPNqbFI9+ECemXSJ/78OnJ+vKzrkvWX339QG5txinHJMfWa8tzLyfrN23JP533ldVXFN0ODkPF8Lv7D5T/gfWPFNsOgGbhCj8gKMIPBEX4gaAIPxAU4QeCIvxAUFxyV6X/ffb23NpP+n8zOfZ9s6fXte1KHwl+h46u+bH3De5P1r+6aVuyftWNn6h52ygXR34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCMrc0187XejGprW7nT23adtrmlnpKbi7z/+bZP0rF86psIFKX5mW/zu8/sGtyZHX/uc/pB96y1MVto1W4g/3yfe8WtV37HHkB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgOM8PjCOc5wdQEeEHgiL8QFCEHwiK8ANBEX4gKMIPBFUx/GY2y8z+y8y2mNmPzezPsuXXmtkLZrY5+7e48e0CKEo1k3YMSbrS3R8zs2MlPWpm67Pal9y9wrdBAGhFFcPv7jsl7cxuD5rZFknpr64B0PIO6zW/mc2WdJakR7JFK83sCTNbY2ZjzkllZt1m1mtmvdo/VFezAIpTdfjN7BhJ35b0WXffK+kmSadJ6tDIM4MvjDXO3XvcvdPdO9XG1IBAq6gq/GY2SSPB/6a73yNJ7r7L3d9092FJX5M0v3FtAihaNe/2m6SbJW1x9y+OWj5j1GqXSOorvj0AjVLN8/AFki6X9KSZbc6WXS1pqZl1aOR7o/slXdGQDgE0RDXv9v9AY39x/P3FtwOgWbjCDwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFRzp+g2e1HST0ctOlHSS01r4PC0am+t2pdEb7Uqsrd3ufs7q1mxqeF/28bNet29s7QGElq1t1btS6K3WpXVG0/7gaAIPxBU2eHvKXn7Ka3aW6v2JdFbrUrprdTX/ADKU/aRH0BJSgm/mS0ys5+Y2bNmdlUZPeQxs34zezKbebi35F7WmNmAmfWNWna8ma03s63ZzzGnSSupt5aYuTkxs3Sp+67VZrxu+tN+M5so6RlJ50naLmmTpKXu/lRTG8lhZv2SOt299HPCZvYhSfsk3eLuc7NlN0ja7e6rsj+c0939L1ukt2sl7St75uZsQpkZo2eWlnSxpI+rxH2X6OtSlbDfyjjyz5f0rLs/5+77Jd0paUkJfbQ8d98oafchi5dIWpvdXquR/zxNl9NbS3D3ne7+WHZ7UNLBmaVL3XeJvkpRRvhnSnp+1P3taq0pv13SA2b2qJl1l93MGE7Opk0/OH36SSX3c6iKMzc30yEzS7fMvqtlxuuilRH+sWb/aaVTDgvcfZ6kCyStyJ7eojpVzdzcLGPMLN0Sap3xumhlhH+7pFmj7p8qaUcJfYzJ3XdkPwck3avWm31418FJUrOfAyX380utNHPzWDNLqwX2XSvNeF1G+DdJOsPM3m1mbZK6JK0roY+3MbP27I0YmVm7pPPVerMPr5O0LLu9TNJ9JfbyFq0yc3PezNIqed+12ozXpVzkk53K+EdJEyWtcfe/a3oTYzCz92jkaC+NTGJ6e5m9mdkdkhZq5FNfuyRdI+k7kr4l6VckbZP0UXdv+htvOb0t1MhT11/O3HzwNXaTe/stSd+X9KSk4Wzx1Rp5fV3avkv0tVQl7Deu8AOC4go/ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANB/R82Ef/avrgdkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f6e444d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#coding: utf-8 \n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "# 加载数据\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# 展示下第一张图\n",
    "# plt.imshow(X_train[0], cmap=plt.get_cmap('PuBuGn_r'))\n",
    "# plt.imshow(X_train[2], cmap=plt.get_cmap('PuBuGn_r'))\n",
    "# print (X_train[1])\n",
    "# print (len(y_train))\n",
    "# print (type(y_train))\n",
    "print ((X_train).size)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('PuBuGn_r'))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (60000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f3f640ad0bc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1591\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1592\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1593\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1594\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1595\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1424\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m                                     exception_prefix='input')\n\u001b[0m\u001b[0;32m   1427\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1428\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    108\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    111\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (60000, 28, 28)"
     ]
    }
   ],
   "source": [
    "#coding: utf-8 #Simple CNN (代码测试通过)\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#加载数据\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][channels][width][height] \n",
    "X_train = X_train.reshape(X_train.shape[0],28, 28,1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0],28, 28,1).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1 \n",
    "X_train = X_train / 255 \n",
    "X_test = X_test / 255 # one hot encode outputs \n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "# 简单的CNN模型\n",
    "def baseline_model():\n",
    "    # create model \n",
    "    model = Sequential()\n",
    "    #卷积层\n",
    "    model.add(Conv2D(32, (3, 3), padding='valid', input_shape=(28, 28,1), activation='relu')) #池化层\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #卷积\n",
    "    model.add(Conv2D(15, (3, 3), padding='valid' ,activation='relu')) #池化\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #全连接，然后输出\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax')) # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# build the model \n",
    "model = baseline_model()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
